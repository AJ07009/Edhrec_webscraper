{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main scrapy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crochet in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: Twisted>=16.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from crochet) (24.3.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from crochet) (1.16.0)\n",
      "Requirement already satisfied: attrs>=21.3.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (23.2.0)\n",
      "Requirement already satisfied: automat>=0.8.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (22.10.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (22.10.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (1.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (4.11.0)\n",
      "Requirement already satisfied: zope-interface>=5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=16.0->crochet) (6.3)\n",
      "Requirement already satisfied: six in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from automat>=0.8.0->Twisted>=16.0->crochet) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet) (3.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from zope-interface>=5->Twisted>=16.0->crochet) (69.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.11.1)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (24.3.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (42.0.7)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (1.9.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (24.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (1.7.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (24.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (6.3)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (0.3.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (69.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from scrapy) (24.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (5.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy) (2.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (23.2.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.0)\n",
      "Requirement already satisfied: automat>=0.8.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.11.0)\n",
      "Requirement already satisfied: idna in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy) (2.0.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy) (3.14.0)\n",
      "Requirement already satisfied: six in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy-selenium in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: scrapy>=1.0.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy-selenium) (2.11.1)\n",
      "Requirement already satisfied: selenium>=3.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy-selenium) (4.20.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (24.3.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (42.0.7)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.9.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (24.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.7.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (24.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (6.3)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (0.3.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (69.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (24.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (5.1.2)\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (5.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scrapy>=1.0.0->scrapy-selenium) (2.0.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=3.9.0->scrapy-selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=3.9.0->scrapy-selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=3.9.0->scrapy-selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=3.9.0->scrapy-selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=3.9.0->scrapy-selenium) (4.11.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->scrapy>=1.0.0->scrapy-selenium) (1.16.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from itemloaders>=1.0.1->scrapy>=1.0.0->scrapy-selenium) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (23.2.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (0.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium>=3.9.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: automat>=0.8.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (22.10.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (22.10.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (1.0.4)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=3.9.0->scrapy-selenium) (1.7.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (2.0.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (3.14.0)\n",
      "Requirement already satisfied: six in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy>=1.0.0->scrapy-selenium) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy>=1.0.0->scrapy-selenium) (3.3.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=3.9.0->scrapy-selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: undetected-chromedriver in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: selenium>=4.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from undetected-chromedriver) (4.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from undetected-chromedriver) (2.31.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from undetected-chromedriver) (12.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected-chromedriver) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->undetected-chromedriver) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->undetected-chromedriver) (3.7)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.9.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected-chromedriver) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.9.0->undetected-chromedriver) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.9.0->undetected-chromedriver) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\josia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josia\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install crochet\n",
    "%pip install scrapy\n",
    "%pip install scrapy-selenium\n",
    "%pip install undetected-chromedriver\n",
    "%pip install pandas\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Iterable\n",
    "import scrapy\n",
    "from scrapy_selenium import SeleniumRequest\n",
    "\n",
    "# Output file formatting\n",
    "class itemFormat(scrapy.Item):\n",
    "    \n",
    "    card_name = scrapy.Field()\n",
    "    percentage_in_decks = scrapy.Field()\n",
    "    img = scrapy.Field()\n",
    "    specials = scrapy.Field()\n",
    "    price_per_kg = scrapy.Field()\n",
    "    \n",
    "    \n",
    "class edhrecSpider(scrapy.Spider):\n",
    "    name = 'searcher'\n",
    "    \n",
    "    custom_settings = {\n",
    "        'FEED_FORMAT': 'json',\n",
    "        'FEED_URI': f'edhrecScrape_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.json'\n",
    "    }\n",
    "    \n",
    "    def start_requests(self) -> Iterable[scrapy.Request]:\n",
    "        # lits all urls that the spider will be crawling through\n",
    "        urls = [ 'https://edhrec.com/commanders/gimli-mournful-avenger' ] # change this link to check through any commanders you want to\n",
    "        \n",
    "        # loop through all the links listed within the urls variable\n",
    "        for url in urls:\n",
    "            yield SeleniumRequest(url = url, callback = self.parse)\n",
    "        return super().start_requests()\n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        for i, quote in enumerate(response.css('div.CardView_cardWrapper__DVSFy')):\n",
    "            quote_item = itemFormat()\n",
    "            \n",
    "            # Extracting product information\n",
    "            quote_item['card_name'] = quote.css('span.Card_name__Mpa7S::text').get(i).replace(\"\\u00f3\",\"o\")\n",
    "            quote_item['percentage_in_decks'] = quote.css('div.CardLabel_label__iAM7T::text').get().replace(\"\\n\", \" || synergy \")\n",
    "            # quote_item['img'] = quote.css('a img.CardImage_border__OcVcj.shadow::attr(src)').get()\n",
    "            \n",
    "            yield quote_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the spider to scrape the site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 16:31:54 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: scrapybot)\n",
      "2024-07-11 16:31:54 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.7, Platform Windows-10-10.0.19045-SP0\n",
      "2024-07-11 16:31:54 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-07-11 16:31:54 [py.warnings] WARNING: c:\\Users\\josia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\utils\\request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2024-07-11 16:31:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-07-11 16:31:54 [scrapy.extensions.telnet] INFO: Telnet Password: f359d85e66cf8061\n",
      "2024-07-11 16:31:54 [py.warnings] WARNING: c:\\Users\\josia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scrapy\\extensions\\feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n",
      "2024-07-11 16:31:54 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-07-11 16:31:54 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2024-07-11 16:31:54 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-07-11 16:31:54 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-07-11 16:31:54 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-07-11 16:31:54 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-07-11 16:31:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-07-11 16:31:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024\n",
      "2024-07-11 16:31:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://edhrec.com/commanders/gimli-mournful-avenger> (referer: None)\n",
      "2024-07-11 16:31:55 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-07-11 16:31:55 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: edhrecScrape_20240711163132.json\n",
      "2024-07-11 16:31:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 259,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 50620,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.066989,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 7, 11, 14, 31, 55, 883431, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 483594,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 11,\n",
      " 'log_count/WARNING': 2,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2024, 7, 11, 14, 31, 54, 816442, tzinfo=datetime.timezone.utc)}\n",
      "2024-07-11 16:31:55 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "    \n",
    "process.crawl(edhrecSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show final product list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File edhrecScrape.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dfjson \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medhrecScrape.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dfjson\n",
      "File \u001b[1;32mc:\\Users\\josia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\josia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\josia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File edhrecScrape.json does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfjson = pd.read_json('edhrecScrape.json')\n",
    "dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def sort_json_file(file_path):\n",
    "    # Read the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Sort items based on a specific attribute, such as 'product_name'\n",
    "    sorted_data = sorted(data, key=lambda x: x['card_name'])\n",
    "\n",
    "    # Write sorted contents back to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(sorted_data, file, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "sort_json_file('edhrecScrape.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only get cards that show up from the user specified percentage and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatPercentage = int(input(\"what percentage of cards do you want to see?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read data from the JSON file into a pandas DataFrame\n",
    "df = pd.read_json('edhrecScrape.json')\n",
    "\n",
    "# Filter the DataFrame based on the percentage condition\n",
    "filtered_df = df[df['percentage_in_decks'].str.extract(r'(\\d+)%', expand=False).astype(float) >= whatPercentage]\n",
    "\n",
    "# Output the filtered DataFrame\n",
    "filtered_df.to_json('filtered_data.json', orient='records')\n",
    "# print(filtered_df.to_dict(orient='records'))\n",
    "\n",
    "filtered_search = pd.read_json('filtered_data.json')\n",
    "filtered_search\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
